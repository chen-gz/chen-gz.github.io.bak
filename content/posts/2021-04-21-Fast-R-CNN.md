---
title: Fast R-CNN
author: Guangzong Chen
date: 2021-04-21 16:00:00 -0400
categories: [Machine Learning]
tags: [ML, RCNN]
math: true
mermaid: true
---

There is already a post about Fast R-CNN paper. Previous one is Fast R-CNN note just for myself.

In this post I will explain the idea of Fast R-CNN and make it very easy to understand.


[papper link](https://arxiv.org/pdf/1504.08083.pdf)

The idea of previous version of R-CNN is very simple. We can easily understand the idea. It is multiple stage network. It have very clear work flow for R-CNN. Proposed regions --> feed to CNN --> classify.

In fast R-CNN some trig is been introduced. First list the advantage or fast R-CNN.

- fast
- training end-to-end.
- any size of input image.
- higher accuracy.

First take a glance of Fast R-CNN architecture.

![](https://raw.githubusercontent.com/chen-gz/picBed/master/20210421190824.png)

Let's explain this architecture from left to right.

As same as R-CNN, the first step of Fast R-CNN is to propose about 2000 regions using selective search. Then feed the whole picture to the CNN feature extractor. The difference between R-CNN and Fast R-CNN is R-CNN only feeds regions to CNN feature extractor, while Fast R-CNN feeds the whole picture. The reason for the R-CNN only feed region is a fully connected layer or SVM requires fixed-size input. Fast R-CNN using RoI pooling to generate fixed output size. That's why it can feed the whole image to the CNN feature extractor. Then Fast R-CNN map the region proposal from the original image to the output of the CNN feature extractor. Because of share compute when computing CNN features, fast R-CNN is much faster than origin R-CNN.

The very important thing to explain is the RoI pooling layer.
How it produces fixed-size output. Actually, it is really easy. It just divides a picture using an SxS grid. (S can be any number here). Then do max pooling in each grid. The output of RoI pooling is an SxS pixel image.

After the RoI pooling layer is fully connected layers. The trick is the last two sibling output layers.

Let's explain these two layers a little bit more. This is multiple tasks architecture. A network has two different outputs and these outputs can help each other to improve the network performance. Definitely, they can harm each other also. So a good loss function is important in this network.

The first output will determine the class, and the second output is the bounding box. The bounding box contains 4 values and it only makes sense when the classifier output is not the background. So the following loss function is used by the author.

$$
L = L_{cls} + \lambda[u \geq 1] L_{loc}
$$

\\(\lambda\\) is a tunable parameter. \\(u \geq 1\\) means only first part output as same as ground true, second part will add to whole loss function.

The total loss combine of two loss function. That's the idea of multi-tasks loss function. The details will not explain here.
