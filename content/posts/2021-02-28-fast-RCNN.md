---
title: Fast R-CNN paper notes
author: Guangzong Chen
date: 2021-02-28 15:03:00 -0500
categories: [Machine Learning]
tags: [ML, RCNN]
math: true
mermaid: true
---

[papper link](https://arxiv.org/abs/1504.08083)

[github link](https://github.com/rbgirshick/fast-rcnn)

## summary

Basic idea is get CNN feature one time instead 2000 times.

In R-CNN it will propose 2000 region, then do classification using CNN. 

It will run about 2000 times CNN. This is very slow proceesion. So in fast R-CNN it only run one time CNN and map the region to feature at the same time. Finally put these region into classification network.

There is a lot detail different between R-CNN and fast R-CNN. Just a summary here and following is the key point in the fast R-CNN paper.

## paper notes


1. Introduction

summary of R-CNN
> Training is a multi-stage pipeline. R-CNN first finetunes a ConvNet on object proposals using log loss. Then, it fits SVMs to ConvNet features. These SVMs act as object detectors, replacing the softmax classifier learnt by fine-tuning. In the third training stage, bounding-box regressors are learned.

Problem of R-CNN (Training is expensive and object detection is slow)
> Training is expensive in space and time. For SVM and bounding-box regressor training, features are extracted from each object proposal in each image and written to disk. With very deep networks, such as VGG16, this process takes 2.5 GPU-days for the $5 

> Object detection is slow. At test-time, features are extracted from each object proposal in each test image. Detection with VGG16 takes $47 \mathrm{~s}$ / image (on a GPU).

**WHY R-CNN so slow**
> R-CNN is slow because it performs a ConvNet forward pass for each object proposal, without sharing computation.


**guangzong comments**

The differnet betweent between SPPnet and fast R-CNN is SPPnet have spatial pyramid pooling, but fast R-CNN jave RoI poolinglayer.

Both of these is trying to solve full connection layer require same size of input.

**end of comments**

Fast R-CNN architecture and training.

![](https://raw.githubusercontent.com/chen-gz/picBed/master/20210228161850.png)

> Fig. 1 illustrates the Fast R-CNN architecture. A Fast R-CNN network takes as input an entire image and a set of object proposals. The network first processes the whole image with several convolutional ( conv) and max pooling layers to produce a conv feature map. Then, for each object proposal a region of interest (RoI) pooling layer extracts a fixed-length feature vector from the feature map. Each feature vector is fed into a sequence of fully connected (fc) layers that finally branch into two sibling output layers: one that produces softmax probability estimates over $K$ object classes plus a catch-all "background" class and another layer that outputs four real-valued numbers for each of the $K$ object classes. Each set of 4 values encodes refined bounding-box positions for one of the $K$ classes.

**most important part**

The idea just divide RoI to serveral pieces (consttant number) and do max poolling in these pieces.

> The RoI pooling layer uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of $H \times W(e . g ., 7 \times 7)$ where $H$ and $W$ are layer hyper-parameters that are independent of any particular RoI. In this paper, an RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple $(r, c, h, w)$ that specifies its top-left corner $(r, c)$ and its height and width $(h, w)$.

> The RoI layer is simply the special-case of the spatial pyramid pooling layer used in SPPnets in which there is only one pyramid level. We use the pooling sub-window calculation given in 11.

**rest of paper are details of implementation and discussion** 
read the paper to understand author's idea


2.2 Initializing from pre-trained networks

2.3 Fine-tuning for detection

> We propose a more efficient training method that takes advantage of feature sharing during training. In Fast RCNN training, stochastic gradient descent (SGD) minibatches are sampled hierarchically, first by sampling $N$ images and then by sampling $R / N$ RoIs from each image.

**Multi-task loss**

rest should read from paper 

**Mini-batch sampling**

**Back-propagation through RoI pooling layers.**

**SGF hyper-parameters**

**Scale invariance**

**Truncated SVD for faster detection**
